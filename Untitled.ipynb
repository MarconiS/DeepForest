{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline to get to use deepforest for species classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepforest\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.read_csv(\"///orange/ewhite/s.marconi/Chapter4//annotations.csv\")\n",
    "annotations = pd.read_csv(\"///orange/ewhite/s.marconi/Chapter4//train_example.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from deepforest import get_data\n",
    "import numpy as np\n",
    "from deepforest import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiffs = annotations[\"image_path\"].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations = [] \n",
    "for ii in tiffs:\n",
    "    tmp= preprocess.split_raster(path_to_raster=\"///orange/ewhite/s.marconi/Chapter4/HSI/HARV/\"+ii,\n",
    "                                 annotations_file=\"///orange/ewhite/s.marconi/Chapter4/annotations.csv\",\n",
    "                                 base_dir='///orange/ewhite/s.marconi/Chapter4//Crops/',\n",
    "                                 patch_size=20,\n",
    "                                 patch_overlap=0.05)\n",
    "    train_annotations.append(pd.DataFrame(tmp)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(644143, 6)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(train_annotations)\n",
    "df.to_csv(\"///orange/ewhite/s.marconi/Chapter4//Crops/train_example.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get training and evaluation from full labelled dataset\n",
    "tiffs = annotations[annotations.columns[0]].drop_duplicates()\n",
    "plots_train = tiffs.sample(n=20000, random_state=1)\n",
    "id_evaluation = annotations[annotations.columns[0]].isin(plots_train)\n",
    "train = annotations[id_evaluation]\n",
    "evaluation = annotations[id_evaluation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"///orange/ewhite/s.marconi/Chapter4//Crops/train_foo2.csv\", index=False, header=False)\n",
    "evaluation.to_csv(\"///orange/ewhite/s.marconi/Chapter4//Crops/evaluation_example.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepforest import deepforest\n",
    "from deepforest import get_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "import deepforest\n",
    "import pandas as pd\n",
    "import os\n",
    "from deepforest import get_data\n",
    "import numpy as np\n",
    "from deepforest import preprocess\n",
    "from deepforest import deepforest\n",
    "from deepforest import get_data\n",
    "\n",
    "\n",
    "train_model = deepforest.deepforest()\n",
    "\n",
    "# Example run with short training\n",
    "train_model.config[\"epochs\"] = 100\n",
    "train_model.config[\"save-snapshot\"] = True\n",
    "train_model.config[\"image-min-side\"] = 400\n",
    "train_model.config[\"image-max-side\"] = 400\n",
    "\n",
    "train_model.config[\"steps\"] = 100\n",
    "\n",
    "\n",
    "train_model.config[\"validation_annotations\"] = \"///orange/ewhite/s.marconi/Chapter4//Crops/evaluation_example.csv\"\n",
    "\n",
    "#test_model.config[\"\"] = \"/Volumes/TOSHIBA EXT/Chapter4/Crops/\"\n",
    "\n",
    "annotations_file = get_data(\"///orange/ewhite/s.marconi/Chapter4//Crops/train_foo.csv\")\n",
    "\n",
    "# Add the following code anywhere in your machine learning file\n",
    "experiment = Experiment(api_key=\"fVhiP3vIQJUBeZyuKJWN9KjSO\",\n",
    "                        project_name=\"d3forhs\", workspace=\"marconis\")\n",
    "\n",
    "experiment.log_parameters(train_model.config)\n",
    "train_model.train(annotations=annotations_file, input_type=\"fit_generator\")#, comet_experiment=comet_experiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_file = \"///orange/ewhite/s.marconi/Chapter4//Crops/evaluation_example.csv\"\n",
    "mAP = train_model.evaluate_generator(annotations=evaluation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "from deepforest import deepforest\n",
    "\n",
    "test_model = deepforest.deepforest()\n",
    "\n",
    "comet_experiment = Experiment(api_key=<api_key>,\n",
    "                                  project_name=<project>, workspace=<\"username\">)\n",
    "\n",
    "comet_experiment.log_parameters(deepforest_model.config)\n",
    "\n",
    "test_model.train(annotations=annotations_file, input_type=\"fit_generator\",comet_experiment=comet_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"///ufrc/ewhite/s.marconi/Chapter4/DeepForest/snapshots/pickle.file\", \"wb\") as f:\n",
    "    pickle.dump(train_model, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path= \"///orange/ewhite/s.marconi/Chapter4/Crops/NEON_D01_HARV_DP3_727000_4701000_reflectance_1837.tif\"\n",
    "with rasterio.open(path, 'r') as ds:\n",
    "    arr = ds.read()\n",
    "    \n",
    "    \n",
    "arr = np.swapaxes(arr,0,1)\n",
    "arr = np.swapaxes(arr,1,2)\n",
    "    \n",
    "npix = arr.shape\n",
    "x = arr\n",
    "x = x.flatten().reshape(npix[0]*npix[1], 369)\n",
    "x = x.astype(np.float32)\n",
    "dat = x**2\n",
    "#normMat = dat.apply(np.sum, axis=1)\n",
    "normMat = np.apply_along_axis(np.sum, 1, dat)\n",
    "normMat = np.power(normMat, 1./2)\n",
    "normMat = np.tile(normMat, (dat.shape[1],1))\n",
    "x= x / np.transpose(normMat)\n",
    "arr = x.reshape(npix[0], npix[1], x.shape[1])\n",
    "dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.477226,  9.643651, 14.491377], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normMat = np.apply_along_axis(np.sum, 1, dat)\n",
    "np.power(normMat, 1./2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
